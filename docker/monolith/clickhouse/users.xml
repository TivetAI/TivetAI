<?xml version="2.0"?>
<clickhouse>
    <!-- Users and roles -->
    <users>
        <default>
            <access_management>1</access_management>
            <password>default</password>
            <profile>default</profile>
            <networks>
                <ip>::/0</ip>
            </networks>
            <quota>default</quota>
            <allow_ddl>1</allow_ddl>
            <allow_introspection>1</allow_introspection>
            <allow_dictionaries>1</allow_dictionaries>
            <databases>
                <database_name>.*</database_name>
            </databases>
        </default>

        <analytics>
            <password>strongpass</password>
            <profile>analytics</profile>
            <networks>
                <ip>192.168.0.0/16</ip>
                <ip>10.0.0.0/8</ip>
            </networks>
            <quota>analytics_quota</quota>
            <databases>
                <database_name>analytics_db</database_name>
            </databases>
        </analytics>

         <!-- Query cache settings -->
    <query_cache_size>104857600</query_cache_size> <!-- 100 MB -->
    <query_cache_min_query_length>100</query_cache_min_query_length>
    <query_cache_ttl>60</query_cache_ttl> <!-- seconds -->

    <!-- HTTP/2 server support -->
    <http_server>
        <enable_http2>1</enable_http2>
        <ssl_cert_file>/etc/clickhouse-server/server.crt</ssl_cert_file>
        <ssl_key_file>/etc/clickhouse-server/server.key</ssl_key_file>
    </http_server>

    <!-- Additional security improvements -->
    <allow_plaintext_password>0</allow_plaintext_password>
    <allow_http_credentials_in_logs>0</allow_http_credentials_in_logs>

        <readonly_user>
            <password>readonly123</password>
            <profile>readonly</profile>
            <networks>
                <ip>172.16.0.0/12</ip>
            </networks>
            <quota>readonly_quota</quota>
            <readonly>1</readonly>
        </readonly_user>

        <!-- Additional users -->

        <data_scientist>
            <password>datasci2025</password>
            <profile>data_scientist</profile>
            <networks>
                <ip>10.1.0.0/16</ip>
            </networks>
            <quota>data_scientist_quota</quota>
            <databases>
                <database_name>analytics_db</database_name>
                <database_name>ml_models</database_name>
            </databases>
            <allow_ddl>0</allow_ddl>
            <allow_introspection>1</allow_introspection>
        </data_scientist>

        <etl_bot>
            <password>etlbotpass</password>
            <profile>etl</profile>
            <networks>
                <ip>10.2.0.0/16</ip>
            </networks>
            <quota>etl_quota</quota>
            <databases>
                <database_name>etl_db</database_name>
            </databases>
            <allow_ddl>1</allow_ddl>
            <allow_introspection>0</allow_introspection>
            <allow_dictionaries>0</allow_dictionaries>
        </etl_bot>
    </users>

    <!-- Profiles define resource and feature limits -->
    <profiles>
        <default>
            <max_memory_usage>10000000000</max_memory_usage>
            <max_execution_time>300</max_execution_time>
            <max_rows_to_read>1000000000</max_rows_to_read>
            <max_threads>8</max_threads>
            <log_queries>1</log_queries>
            <load_balancing>random</load_balancing>
            <use_uncompressed_cache>1</use_uncompressed_cache>
            <allow_introspection_functions>1</allow_introspection_functions>
        </default>

        <analytics>
            <max_memory_usage>20000000000</max_memory_usage>
            <max_bytes_before_external_group_by>5000000000</max_bytes_before_external_group_by>
            <max_network_bandwidth>100000000</max_network_bandwidth>
            <load_balancing>random</load_balancing>
            <use_uncompressed_cache>1</use_uncompressed_cache>
            <join_algorithm>hash</join_algorithm>
            <max_threads>12</max_threads>
            <max_execution_time>600</max_execution_time>
            <allow_introspection_functions>1</allow_introspection_functions>
            <distributed_aggregation_memory_efficient>1</distributed_aggregation_memory_efficient>
        </analytics>

        <readonly>
            <readonly>1</readonly>
            <log_queries>0</log_queries>
            <max_memory_usage>2000000000</max_memory_usage>
            <max_execution_time>60</max_execution_time>
            <max_threads>4</max_threads>
            <allow_introspection_functions>0</allow_introspection_functions>
        </readonly>

        <data_scientist>
            <max_memory_usage>15000000000</max_memory_usage>
            <max_execution_time>1200</max_execution_time>
            <max_rows_to_read>2000000000</max_rows_to_read>
            <max_threads>10</max_threads>
            <log_queries>1</log_queries>
            <allow_introspection_functions>1</allow_introspection_functions>
            <load_balancing>nearest_hostname</load_balancing>
            <join_algorithm>hash</join_algorithm>
        </data_scientist>

        <etl>
            <max_memory_usage>8000000000</max_memory_usage>
            <max_execution_time>1800</max_execution_time>
            <max_threads>6</max_threads>
            <log_queries>0</log_queries>
            <allow_introspection_functions>0</allow_introspection_functions>
            <distributed_aggregation_memory_efficient>1</distributed_aggregation_memory_efficient>
        </etl>
    </profiles>

    <!-- Quotas to control usage per role -->
    <quotas>
        <default>
            <interval>
                <duration>3600</duration>
                <queries>0</queries>
                <errors>0</errors>
                <result_rows>0</result_rows>
                <read_rows>0</read_rows>
                <execution_time>0</execution_time>
            </interval>
        </default>

        <analytics_quota>
            <interval>
                <duration>3600</duration>
                <queries>10000</queries>
                <execution_time>10000</execution_time>
                <read_rows>1000000000</read_rows>
            </interval>
        </analytics_quota>

        <readonly_quota>
            <interval>
                <duration>3600</duration>
                <queries>1000</queries>
                <execution_time>3600</execution_time>
                <read_rows>500000000</read_rows>
            </interval>
        </readonly_quota>

        <data_scientist_quota>
            <interval>
                <duration>3600</duration>
                <queries>5000</queries>
                <execution_time>15000</execution_time>
                <read_rows>2000000000</read_rows>
            </interval>
        </data_scientist_quota>

        <etl_quota>
            <interval>
                <duration>3600</duration>
                <queries>20000</queries>
                <execution_time>20000</execution_time>
                <read_rows>3000000000</read_rows>
            </interval>
        </etl_quota>
    </quotas>

    <!-- Settings overrides per user if needed -->
    <user_directories>
        <users_xml>
            <path>users.xml</path>
        </users_xml>
    </user_directories>

    <!-- Global connection limits -->
    <max_connections>2048</max_connections>
    <keep_alive_timeout>10</keep_alive_timeout>
    <max_concurrent_queries>512</max_concurrent_queries>
    <max_session_memory_usage>1500000000</max_session_memory_usage>

    <!-- Security-related settings -->
    <http_server_default_response>Access Denied</http_server_default_response>
    <allow_plaintext_password>0</allow_plaintext_password>
    <allow_http_credentials_in_logs>0</allow_http_credentials_in_logs>
    <display_name>ClickHouse Access Node</display_name>

    <!-- External dictionaries access -->
    <dictionaries_config>/etc/clickhouse-server/dictionaries/*.xml</dictionaries_config>

    <!-- Enable audit logging -->
    <audit_log>
        <database>system</database>
        <table>audit_log</table>
        <flush_interval_milliseconds>10000</flush_interval_milliseconds>
    </audit_log>

    <!-- Enable session control -->
    <session_settings>
        <idle_timeout>600</idle_timeout>
        <client_idle_timeout>300</client_idle_timeout>
        <session_close_on_exit>1</session_close_on_exit>
        <max_sessions>1000</max_sessions>
    </session_settings>

    <!-- Add optional telemetry -->
    <send_crash_reports>1</send_crash_reports>
    <send_metrics_interval_seconds>60</send_metrics_interval_seconds>

    <!-- Enable query log for monitoring -->
    <query_log>
        <database>system</database>
        <table>query_log</table>
        <flush_interval_milliseconds>10000</flush_interval_milliseconds>
    </query_log>

    <!-- Enable query thread log -->
    <query_thread_log>
        <database>system</database>
        <table>query_thread_log</table>
        <flush_interval_milliseconds>10000</flush_interval_milliseconds>
    </query_thread_log>

    <!-- Enable trace log -->
    <trace_log>
        <database>system</database>
        <table>trace_log</table>
        <flush_interval_milliseconds>10000</flush_interval_milliseconds>
    </trace_log>

    <!-- Enable text log -->
    <text_log>
        <database>system</database>
        <table>text_log</table>
        <flush_interval_milliseconds>10000</flush_interval_milliseconds>
    </text_log>

    <!-- Experimental features toggle -->
    <experimental>
        <enable_materialized_view_refresh>1</enable_materialized_view_refresh>
        <use_index_for_in_with_subqueries>1</use_index_for_in_with_subqueries>
    </experimental>

    <!-- Alerts and monitoring -->
    <alerts>
        <send_email>0</send_email>
        <send_slack>0</send_slack>
        <alert_emails></alert_emails>
        <alert_slack_webhook></alert_slack_webhook>
    </alerts>

</clickhouse>
